{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID2222 - Homework 1\n",
    "\n",
    "You are to implement the stages of finding textually similar documents based on Jaccard similarity using the shingling, minhashing, and locality-sensitive hashing (LSH) techniques and corresponding algorithms. The implementation can be done using any big data processing framework, such as Apache Spark, Apache Flink, or no framework, e.g., in Java, Python, etc. To test and evaluate your implementation, write a program that uses your implementation to find similar documents in a corpus of 5-10 or more documents such as web pages or emails.\n",
    "\n",
    "The stages should be implemented as a collection of classes, modules, functions or procedures depending the framework and the language of your choice. Below, we give a description of sample classes that implement different stages of finding textually similar documents. You do not have to develop the exact same classes and data types as described below. Feel free to use data structures that suit you best.\n",
    "\n",
    "1. A class Shingling that constructs k–shingles of a given length k (e.g., 10) from a given document, computes a hash value for each unique shingle, and represents the document in the form of an ordered set of its hashed k-shingles.\n",
    "2. A class CompareSets that computes the Jaccard similarity of two sets of integers – two sets of hashed shingles.\n",
    "3. A class MinHashing that builds a minHash signature (in the form of a vector or a set) of a given length n from a given set of integers (a set of hashed shingles).\n",
    "4. A class CompareSignatures that estimates similarity of two integer vectors – minhash signatures – as a fraction of components, in which they agree.\n",
    "5. (Optional task for extra 2 bonus) A class LSH that implements the LSH technique: given a collection of minhash signatures (integer vectors) and a similarity threshold t, the LSH class (using banding and hashing) finds all candidate pairs of signatures that agree on at least fraction t of their components.\n",
    "\n",
    "To test and evaluate scalability (the execution time versus the size of input dataset) of your implementation, write a program that uses your classes to find similar documents in a corpus of 5-10 documents. Choose a similarity threshold s (e.g., 0,8) that states that two documents are similar if the Jaccard similarity of their shingle sets is at least s. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalability\n",
    "To test and evaluate scalability (the execution time versus the size of input dataset) of your implementation, write a program that uses your classes to find similar documents in a corpus of 5-10 documents. Choose a similarity threshold s (e.g., 0,8) that states that two documents are similar if the Jaccard similarity of their shingle sets is at least s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_and_prepare_data(path):\n",
    "    with open(\"train-v2.0.json\") as f:\n",
    "        d = f.read()\n",
    "        data = json.loads(d)\n",
    "\n",
    "    characters = {}\n",
    "    for d in data['data']:\n",
    "        info = d['paragraphs'][0]['context']\n",
    "\n",
    "        characters[d['title']] = info\n",
    "\n",
    "    return characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_business():\n",
    "    path = \"bbc-full-text-document-classification/bbc/business\"\n",
    "    file_list = os.listdir(path)\n",
    "    \n",
    "    data = {}\n",
    "    \n",
    "    for file in file_list:\n",
    "        with open(os.path.join(path, file)) as f:\n",
    "            data[file.split(\".\")[0]] = f.read().replace('\\n', ' ').lower()\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_business()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = load_and_prepare_data(\"train-v2.0.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import binascii\n",
    "import time\n",
    "\n",
    "class Shingling:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        self.docs_shingles = {}\n",
    "        self.doc_names = []\n",
    "        \n",
    "    def _clean(self, doc):\n",
    "        \"\"\"\n",
    "        Some rules for cleaning the text:\n",
    "        https://www.cs.utah.edu/~jeffp/teaching/cs5955/L4-Jaccard+Shingle.pdf\n",
    "        \"\"\"\n",
    "        doc = doc.lower()\n",
    "        doc = doc.replace(\" \", \"_\")\n",
    "        return doc\n",
    "    \n",
    "    def _tokenize(self, doc):\n",
    "        \"\"\"\n",
    "        Construct the shingles based on k-characters\n",
    "        \"\"\"\n",
    "        sh = set()\n",
    "        if len(doc) >= self.k:\n",
    "            for idx, token in enumerate(doc):\n",
    "                if idx + self.k <= len(doc):\n",
    "                    sh.add(self._hash(doc[idx:idx + self.k]))\n",
    "\n",
    "        return sh\n",
    "\n",
    "    def _hash(self, shingle):\n",
    "        \"\"\"\n",
    "        Compute hash values for the shingle\n",
    "        \"\"\"\n",
    "        return binascii.crc32(shingle.encode(\"utf-8\")) & 0xffffffff\n",
    "    \n",
    "    def generate_shingles(self, doc):\n",
    "        doc = self._clean(doc)\n",
    "        shingles = self._tokenize(doc)\n",
    "        \n",
    "        return shingles  \n",
    "    \n",
    "    def generate_shingles_for_docs(self, docs):\n",
    "        \"\"\"\n",
    "        Takes in docs in the form of a dict of {\"docID\": \"doc string\"}\n",
    "        \"\"\"\n",
    "        print(\"Shingling {} articles...\".format(len(docs)))\n",
    "\n",
    "        t0 = time.time()\n",
    "        for k, v in docs.items():\n",
    "            self.doc_names.append(k)\n",
    "            d = self._clean(v)\n",
    "            d = self._tokenize(d)\n",
    "    \n",
    "            self.docs_shingles[k] = d\n",
    "    \n",
    "        print ('\\nShingling took %.2f sec.' % (time.time() - t0))\n",
    "\n",
    "    @staticmethod\n",
    "    def compare_sets(s1, s2):\n",
    "        \"\"\"\n",
    "        Compute Jaccard Similarity\n",
    "        n(intersection) / n(union)\n",
    "        \"\"\"\n",
    "        # add in some checks \n",
    "        jacc_sim = (len(s1.intersection(s2)) / float(len(s1.union(s2))))\n",
    "        return jacc_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "shing = Shingling(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shingling 510 articles...\n",
      "\n",
      "Shingling took 2.63 sec.\n"
     ]
    }
   ],
   "source": [
    "shing.generate_shingles_for_docs(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14781834372217276"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shing.compare_sets(shing.docs_shingles[shing.doc_names[1]],\n",
    "                   shing.docs_shingles[shing.doc_names[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_jaccard_sim(docs_shingles, doc_names):\n",
    "    print(\"Calculating the Jaccard Similarity for all documents\")\n",
    "    dataset_size = len(docs_shingles)\n",
    "\n",
    "    jaccSimMatrix = np.zeros(dataset_size * dataset_size).reshape(dataset_size,dataset_size)\n",
    "    t0 = time.time()\n",
    "\n",
    "    docKeys = list(docs_shingles.keys())\n",
    "    for j in range(0, len(doc_names)):    \n",
    "        s1 = docs_shingles[doc_names[j]]\n",
    "        for k in range(j, len(doc_names)):\n",
    "            s2 = docs_shingles[doc_names[k]]\n",
    "            jacc_sim = (len(s1.intersection(s2)) / float(len(s1.union(s2))))\n",
    "            jaccSimMatrix[j, k] = jacc_sim\n",
    "            jaccSimMatrix[k, j] = jacc_sim\n",
    "\n",
    "    print ('\\nJaccard Similarity for ' + str(len(doc_names)) + ' docs took %.2f sec.' % (time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jaccSimMatrix  = generate_jaccard_sim(shing.docs_shingles, shing.doc_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinHashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "class MinHashing:\n",
    "    \n",
    "    def __init__(self, n, max_shingle_ID = 2**32-1):\n",
    "        self.n = n # number of hashes\n",
    "        self.max_shingle_ID = max_shingle_ID # the max number\n",
    "        self.next_prime = 4294967311 # the next prime number after max shingle ID\n",
    "        self.coeffs_A = self.generate_coeffs()\n",
    "        self.coeffs_B = self.generate_coeffs()\n",
    "        self.docs_minhash_signatures = {}\n",
    "    \n",
    "    def generate_coeffs(self):\n",
    "        \"\"\"\n",
    "        Create a list of 'n' unique random values.\n",
    "        \"\"\"\n",
    "        coeffs_list = []\n",
    "        \n",
    "        for _ in range(self.n):\n",
    "            # TODO: check if it a good idea to have 0 for coeff A\n",
    "            rand_idx = random.randint(0, self.max_shingle_ID)\n",
    "\n",
    "            # Ensure that each random number is unique.\n",
    "            while rand_idx in coeffs_list:\n",
    "                rand_idx = random.randint(0, self.max_shingle_ID)\n",
    "\n",
    "            coeffs_list.append(rand_idx)\n",
    "\n",
    "        return coeffs_list\n",
    "\n",
    "    def _minHash_function(self, pos, x):\n",
    "        \"\"\"\n",
    "        Return a hash in the form of (ax+b) % prime\n",
    "        \"\"\"\n",
    "        return (self.coeffs_A[pos] * x + self.coeffs_B[pos]) % self.next_prime\n",
    "        \n",
    "    def generate_signature(self, shingle_set):\n",
    "        \"\"\"\n",
    "        Given a shingle set of IDs, generate the hashes and compute the minimum hash\n",
    "        \"\"\"\n",
    "        signature = []\n",
    "        \n",
    "        for i in range(self.n):\n",
    "            signature.append(min(map(lambda x: self._minHash_function(i,x), shingle_set)))\n",
    "\n",
    "        return signature\n",
    "    \n",
    "    def generate_doc_signatures(self, shingles):\n",
    "        print(\"Generating MinHash signatures for documents..\")\n",
    "        t0 = time.time()\n",
    "\n",
    "        for k, v in shingles.items():\n",
    "            self.docs_minhash_signatures[k] = self.generate_signature(v)\n",
    "       \n",
    "        print ('\\n Generating Signatures for ' + str(len(shingles)) + ' docs took %.2f sec.' % (time.time() - t0))\n",
    "\n",
    "    @staticmethod\n",
    "    def compare_signatures(s1, s2):\n",
    "        if not len(s1) == len(s2):\n",
    "            print(\"Unequal length of Signature\")\n",
    "            \n",
    "        equality = 0\n",
    "        signature_len = len(s1)\n",
    "        for x, y in zip(s1, s2):\n",
    "            if(x == y):\n",
    "                equality += 1 \n",
    "        return equality / float(signature_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "minhash = MinHashing(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[869666,\n",
       " 556469,\n",
       " 3534900,\n",
       " 3890139,\n",
       " 5378602,\n",
       " 470916,\n",
       " 1322947,\n",
       " 6030977,\n",
       " 4909494,\n",
       " 2766997,\n",
       " 3888081,\n",
       " 4574207,\n",
       " 4569552,\n",
       " 847551,\n",
       " 2533533,\n",
       " 2057741,\n",
       " 1458543,\n",
       " 148928,\n",
       " 318836,\n",
       " 302128,\n",
       " 468841,\n",
       " 7600415,\n",
       " 839921,\n",
       " 2079849,\n",
       " 1844037,\n",
       " 364503,\n",
       " 737076,\n",
       " 576240,\n",
       " 10773298,\n",
       " 389991,\n",
       " 2060149,\n",
       " 555564,\n",
       " 852796,\n",
       " 698145,\n",
       " 2708435,\n",
       " 10712510,\n",
       " 625492,\n",
       " 5101586,\n",
       " 3223696,\n",
       " 50099,\n",
       " 866641,\n",
       " 3670445,\n",
       " 4118320,\n",
       " 329929,\n",
       " 1689569,\n",
       " 355086,\n",
       " 1310794,\n",
       " 3570832,\n",
       " 290250,\n",
       " 4078725,\n",
       " 1352298,\n",
       " 206529,\n",
       " 5302739,\n",
       " 1690114,\n",
       " 1254015,\n",
       " 1321394,\n",
       " 3877513,\n",
       " 3406763,\n",
       " 2888095,\n",
       " 2532844,\n",
       " 4689460,\n",
       " 1625310,\n",
       " 5338377,\n",
       " 3575923,\n",
       " 2591847,\n",
       " 2270034,\n",
       " 8891202,\n",
       " 420527,\n",
       " 1753523,\n",
       " 1150765,\n",
       " 207593,\n",
       " 3502670,\n",
       " 218353,\n",
       " 1729106,\n",
       " 71995,\n",
       " 870603,\n",
       " 3230584,\n",
       " 5711224,\n",
       " 5675339,\n",
       " 10251265,\n",
       " 85060,\n",
       " 548180,\n",
       " 2122877,\n",
       " 2497270,\n",
       " 7754836,\n",
       " 2450101,\n",
       " 2081333,\n",
       " 3063637,\n",
       " 4199246,\n",
       " 645335,\n",
       " 614416,\n",
       " 8294555,\n",
       " 779118,\n",
       " 2612049,\n",
       " 202906,\n",
       " 677139,\n",
       " 1530834,\n",
       " 336051,\n",
       " 3688991,\n",
       " 1236558]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minhash.generate_signature(shing.docs_shingles[shing.doc_names[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minhash.compare_signatures(minhash.generate_signature(shing.docs_shingles[shing.doc_names[1]]),\n",
    "                   minhash.generate_signature(shing.docs_shingles[shing.doc_names[2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating MinHash signatures for documents..\n",
      "\n",
      " Generating Signatures for 510 docs took 63.51 sec.\n"
     ]
    }
   ],
   "source": [
    "minhash.generate_doc_signatures(shing.docs_shingles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSH\n",
    "Partition into Bands\n",
    "- Divide matrix M into b bands of r rows.\n",
    "- For each band, hash its portion of each column to a hash table with k buckets.\n",
    "- Make k as large as possible.\n",
    "- Candidate column pairs are those that hash to the same bucket for a number of bands with regards to the threshold set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class LSH:\n",
    "    \n",
    "    def __init__(self, band_size, row_size, threshold):\n",
    "        self.band_size = band_size\n",
    "        self.threshold = threshold\n",
    "        self.row_size = row_size\n",
    "        self.docs_lsh = {}\n",
    "        self.candidate_pairs = defaultdict(set)\n",
    "\n",
    "    def get_lsh(self, signature):\n",
    "        lsh = []\n",
    "        for i in range(self.band_size):\n",
    "            lsh.append(hash(tuple(signature[i*self.row_size:(i*self.row_size+self.row_size)])) % 4294967311)\n",
    "        return lsh\n",
    "\n",
    "    def get_lsh_for_docs(self, signatures):\n",
    "        for k, v in signatures.items():\n",
    "            self.docs_lsh[k] = self.get_lsh(v)\n",
    "        \n",
    "    def generate_candidate_pairs(self, t=0.0002):\n",
    "        \"\"\"\n",
    "        t: the fraction of components that pair of signatures agrees on\n",
    "        \"\"\"\n",
    "        all_docs = list(self.docs_lsh.values())\n",
    "        all_names = list(self.docs_lsh.keys())\n",
    "        \n",
    "        # Minimum number of bands that should has overlap\n",
    "        # hash according to the threshold set\n",
    "        threshold = t * self.band_size\n",
    "\n",
    "        # Stores the intermediate number of band overlaps\n",
    "        pairs = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "        for idx, s1 in enumerate(all_docs):\n",
    "            s1_name = all_names[idx]\n",
    "            \n",
    "            # Sliding count to perform comparison\n",
    "            for curr_iter, s2 in enumerate(all_docs[idx + 1:]):\n",
    "                s2_name = all_names[curr_iter + idx + 1]\n",
    "                \n",
    "                for x, y in zip(s1, s2):\n",
    "                    if(x == y):\n",
    "                        if not pairs[s1_name][s2_name]:\n",
    "                            pairs[s1_name][s2_name] = 1\n",
    "                        else:\n",
    "                            pairs[s1_name][s2_name] += 1\n",
    "\n",
    "                # Store pairs that is above the threshold as candidate pairs\n",
    "                if pairs[s1_name][s2_name] > threshold:\n",
    "                    self.candidate_pairs[s1_name].add(s2_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lshh = LSH(10, 10, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3095441960,\n",
       " 823489805,\n",
       " 4257584683,\n",
       " 3143060384,\n",
       " 974132344,\n",
       " 814869834,\n",
       " 2755579486,\n",
       " 801032633,\n",
       " 3117601178,\n",
       " 3867275264]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lshh.get_lsh(minhash.docs_minhash_signatures[shing.doc_names[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lshh.get_lsh_for_docs(minhash.docs_minhash_signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3095441960,\n",
       " 823489805,\n",
       " 4257584683,\n",
       " 3143060384,\n",
       " 974132344,\n",
       " 814869834,\n",
       " 2755579486,\n",
       " 801032633,\n",
       " 3117601178,\n",
       " 3867275264]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lshh.docs_lsh[shing.doc_names[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lshh.generate_candidate_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'007': {'253'},\n",
       "             '214': {'240'},\n",
       "             '215': {'494'},\n",
       "             '229': {'209'},\n",
       "             '258': {'356'},\n",
       "             '260': {'354'},\n",
       "             '265': {'333'},\n",
       "             '267': {'365'},\n",
       "             '371': {'256'},\n",
       "             '416': {'292'},\n",
       "             '438': {'290'},\n",
       "             '493': {'286'}})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lshh.candidate_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This article:\n",
      "\n",
      " shares rise on new man utd offer  shares in manchester united closed up 4.75% on monday following a new offer from us tycoon malcolm glazer.  the board of the football club is expected to meet early this week to discuss the latest proposal, which values the club at £800m ($1.5bn). manchester united revealed on sunday that it had received a detailed proposal from mr glazer, which looks set to receive more serious scrutiny. the club has previously rejected mr glazer's approaches out of hand. but a senior source at the club told the bbc: \"this time it's different.\" supporters' group shareholders united, however, urged the club to reject the new deal.  a spokesman for the shareholders united said: \"i can't see any difference (compared to mr glazer's previous proposals) other than £200m less debt. \"he isn't bringing any money into the club; he'll use our money to buy it.\"  mr glazer's latest move is being led by mr glazer's two sons, avi and joel, according to the financial times. a proposal was received by david gill, united's chief executive, at the end of last week, pitched at about 300p a share. david cummings, head of uk equities for standard life investments, said he believed a \"well funded\" 300p a share bid would be enough for mr glazer to take control of the club.  \"i do not think there is anything that manchester united fans can do about it,\" he told the bbc. \"they can complain about it but it is curtains for them. they may not want him but they are going to get him.\" the us tycoon, who has been wooing the club for the last 12 months, has approached the united board with \"detailed proposals\", it has confirmed.  mr glazer, who owns the tampa bay buccaneers team, hopes this will lead to a formal bid being accepted. he is believed to have increased the amount of equity in the new proposal, though it is not clear by how much. for his proposal to succeed, he needs the support of united's largest shareholders, the irish horseracing tycoons jp mcmanus and john magnier. they own 29% of united through their cubic expression investment vehicle. mr glazer and his family hold a stake of 28.1%. but it is not yet known whether mr mcmanus and mr magnier would support a glazer bid. nm rothschild, the investment bank, is advising mr glazer, according to the financial times. his previous adviser, jpmorgan, quit last year when mr glazer went ahead and voted against the appointment of three united directors to the board, against its advice. but the ft said it thought jp morgan may still have had some role in financing mr glazer's latest financial proposal. \n",
      "\n",
      "\n",
      "is similar to:\n",
      "  mixed reaction to man utd offer  shares in manchester united were up over 5% by noon on monday following a new offer from malcolm glazer.  the board of man utd is expected to meet early this week to discuss the latest proposal from the us tycoon that values the club at £800m ($1.5bn). manchester united revealed on sunday that it had received a detailed proposal from mr glazer. a senior source at the club told the bbc: \"this time it's different\". the board is obliged to consider this deal. but the man utd supporters club urged the club to reject the new deal. manchester united past and present footballers eric cantona and ole gunnar solskjaer, and club manager sir alex ferguson, have lent their backing to the supporters' group, shareholders united. they have all spoken out against the bid.  a spokesman for the supporters club said: \"i can't see any difference (compared to mr glazer's previous proposals) other than £200m less debt. \"he isn't bringing any money into the club; he'll use our money to buy it.\"  mr glazer's latest move is being led by mr glazer's two sons, avi and joel, according to the financial times. a proposal was received by david gill, united's chief executive, at the end of last week, pitched at about 300p a share. david cummings, head of uk equities for standard life investments, said he believed a \"well funded\" 300p a share bid would be enough for mr glazer to take control of the club. \"i do not think there is anything that manchester united fans can do about it,\" he told the bbc. \"they can complain about it but it is curtains for them. they may not want him but they are going to get him.\" the us tycoon, who has been wooing the club for the last 12 months, has approached the united board with \"detailed proposals\", it has confirmed.  mr glazer, who owns the tampa bay buccaneers team, hopes this will lead to a formal bid being accepted. he is believed to have increased the amount of equity in the new proposal, though it is not clear by how much. for his proposal to succeed, he needs the support of united's largest shareholders, the irish horseracing tycoons jp mcmanus and john magnier. they own 29% of united through their cubic expression investment vehicle. mr glazer and his family hold a stake of 28.1%. but it is not yet known whether mr mcmanus and mr magnier would support a glazer bid. nm rothschild, the investment bank, is advising mr glazer, according to the financial times. his previous adviser, jpmorgan, quit last year when mr glazer went ahead and voted against the appointment of three united directors to the board, against its advice. but the ft said it thought jp morgan may still have had some role in financing mr glazer's latest financial proposal. \n"
     ]
    }
   ],
   "source": [
    "print(\"This article:\\n\\n\", dataset['229'])\n",
    "print(\"\\n\\nis similar to:\\n \", dataset['209'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
